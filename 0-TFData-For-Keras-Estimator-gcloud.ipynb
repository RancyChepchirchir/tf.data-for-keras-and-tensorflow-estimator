{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial for using TF.Data, Keras, Estimator, and Google storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have TF >= 1.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please install tf-nightly-gpu by ```pip install --upgrade tf-nightly``` if you have TF < 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Data & Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28) (60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and Y are usually prepared in float32 & int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000 784 10\n"
     ]
    }
   ],
   "source": [
    "nClass = 10\n",
    "nData_train = x_train.shape[0]\n",
    "nData_test = x_test.shape[0]\n",
    "nDimIn = x_train.shape[1]*x_train.shape[2]\n",
    "nDimOut = nClass\n",
    "print(nData_train, nData_test, nDimIn, nDimOut) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myModel():\n",
    "    dataIn = keras.Input(shape=(nDimIn,), name='X')\n",
    "    fc1 = keras.layers.Dense(40, activation='relu', name='fc1')(dataIn)\n",
    "    fc2 = keras.layers.Dense(40, activation='relu', name='fc2')(fc1)\n",
    "    dataOut = keras.layers.Dense(nDimOut, activation='softmax', name='dataOut')(fc2)\n",
    "    model = keras.Model(inputs=dataIn, outputs=dataOut, name='Y')\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "batchSize = 64\n",
    "nEpoch = 5\n",
    "nSteps = (int)(nData_train/batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of steps for training & testing each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nStep_train = (int)(nData_train/batchSize)\n",
    "nStep_test = (int)(nData_test/batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 40)                31400     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dataOut (Dense)              (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 33,450\n",
      "Trainable params: 33,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = myModel()\n",
    "model.summary()\n",
    "del model\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using Keras with tf.data from numpy data on the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMapFunc_npy(xx, yy):\n",
    "    norm = tf.constant(255, dtype=tf.float32, shape=(nDimIn,))\n",
    "    xx = tf.div(tf.reshape(xx, [-1]), norm)\n",
    "    yy = tf.one_hot(yy, nClass)\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare train and test datasets using tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle 10000 instances -> data transformation (e.g. normalization) -> minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "data_train = data_train.shuffle(10000).map(myMapFunc_npy).batch(batchSize).repeat()\n",
    "data_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "data_test = data_test.shuffle(10000).map(myMapFunc_npy).batch(batchSize).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.3820 - acc: 0.8890 - val_loss: 0.2067 - val_acc: 0.9387\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.1763 - acc: 0.9484 - val_loss: 0.1485 - val_acc: 0.9553\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.1366 - acc: 0.9595 - val_loss: 0.1286 - val_acc: 0.9596\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.1124 - acc: 0.9664 - val_loss: 0.1150 - val_acc: 0.9660\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0949 - acc: 0.9706 - val_loss: 0.1151 - val_acc: 0.9651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f96457a7d68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train, epochs=nEpoch, validation_data=data_test, steps_per_epoch=nStep_train, validation_steps=nStep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_train, data_test, model\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Keras with tf.data from TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. Write a TFRecord file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "def _float_feature(array):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=array))\n",
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def myWriteTFRecord(filename, xx, yy):\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for ii in range(len(yy)):\n",
    "        myFeat = tf.train.Features(feature={\n",
    "                    'X': _float_feature(xx[ii]),\n",
    "                    'Y': _int64_feature(yy[ii])})\n",
    "        example = tf.train.Example(features=myFeat)\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data should have 2-dim, (N*D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vec = x_train.reshape([nData_train,-1])\n",
    "x_test_vec = x_test.reshape([nData_test,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = 'mnist_train.tfrecords'\n",
    "file_test = 'mnist_test.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "myWriteTFRecord(file_train, x_train_vec, y_train)\n",
    "myWriteTFRecord(file_test, x_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. Training from the TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMapFunc_onehot(example):\n",
    "    feature_def = {'X': tf.FixedLenFeature(nDimIn, tf.float32),\n",
    "                   'Y': tf.FixedLenFeature(1, tf.int64)}\n",
    "    features = tf.parse_single_example(example, feature_def)\n",
    "    norm = tf.constant(255, dtype=tf.float32, shape=(nDimIn,))\n",
    "    xx = tf.div(features['X'], norm)\n",
    "    yy = tf.reshape(tf.one_hot(features['Y'], nClass, dtype=tf.float32), [-1])\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare train and test datasets using tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = tf.data.TFRecordDataset(file_train)\n",
    "data_train = data_train.shuffle(nData_train).map(myMapFunc_onehot).batch(batchSize).repeat()\n",
    "data_test = tf.data.TFRecordDataset(file_test)\n",
    "data_test = data_test.shuffle(nData_test).map(myMapFunc_onehot).batch(batchSize).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 8s 8ms/step - loss: 0.3822 - acc: 0.8900 - val_loss: 0.2071 - val_acc: 0.9393\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.1816 - acc: 0.9478 - val_loss: 0.1566 - val_acc: 0.9508\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 8s 8ms/step - loss: 0.1345 - acc: 0.9604 - val_loss: 0.1308 - val_acc: 0.9619\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 8s 8ms/step - loss: 0.1096 - acc: 0.9673 - val_loss: 0.1208 - val_acc: 0.9643\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 8s 8ms/step - loss: 0.0929 - acc: 0.9723 - val_loss: 0.1053 - val_acc: 0.9696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9634ed9cf8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train, epochs=nEpoch, validation_data=data_test, steps_per_epoch=nStep_train, validation_steps=nStep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_train, data_test, model\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using a pre-made estimator with tf.data from TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMapFunc_scalar(example):\n",
    "    feature_def = {'X': tf.FixedLenFeature(nDimIn, tf.float32),\n",
    "                   'Y': tf.FixedLenFeature(1, tf.int64)}\n",
    "    features = tf.parse_single_example(example, feature_def)\n",
    "    norm = tf.constant(255, dtype=tf.float32, shape=(nDimIn,))\n",
    "    xx = tf.div(features['X'], norm)\n",
    "    yy = features['Y']\n",
    "    return {'X': xx}, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF Estimator require an input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myInputFunc_scalar(filename,numData):\n",
    "    data_temp = tf.data.TFRecordDataset(filename)\n",
    "    data_temp = data_temp.shuffle(buffer_size=numData).map(myMapFunc_scalar).batch(batchSize).repeat()\n",
    "    return data_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpcj7___ya\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_eval_distribute': None, '_log_step_count_steps': 100, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9634bc95c0>, '_model_dir': '/tmp/tmpcj7___ya', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_train_distribute': None, '_protocol': None, '_evaluation_master': '', '_save_checkpoints_steps': None, '_service': None, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_is_chief': True, '_save_checkpoints_secs': 600, '_master': '', '_tf_random_seed': None, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_experimental_distribute': None, '_global_id_in_cluster': 0}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column('X', shape=[784,])]\n",
    "estimator = tf.estimator.DNNClassifier(\n",
    " feature_columns=feature_columns,\n",
    " hidden_units=[40, 40],\n",
    " optimizer=tf.train.AdamOptimizer(0.001),\n",
    " n_classes=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpcj7___ya/model.ckpt.\n",
      "INFO:tensorflow:loss = 149.6716, step = 0\n",
      "INFO:tensorflow:global_step/sec: 149.576\n",
      "INFO:tensorflow:loss = 30.462986, step = 100 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.669\n",
      "INFO:tensorflow:loss = 15.723204, step = 200 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.861\n",
      "INFO:tensorflow:loss = 25.859535, step = 300 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.054\n",
      "INFO:tensorflow:loss = 28.355984, step = 400 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.849\n",
      "INFO:tensorflow:loss = 14.388325, step = 500 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.55\n",
      "INFO:tensorflow:loss = 10.755209, step = 600 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.504\n",
      "INFO:tensorflow:loss = 15.831234, step = 700 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.786\n",
      "INFO:tensorflow:loss = 12.951447, step = 800 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.997\n",
      "INFO:tensorflow:loss = 12.315826, step = 900 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.125\n",
      "INFO:tensorflow:loss = 9.19237, step = 1000 (0.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.461\n",
      "INFO:tensorflow:loss = 7.662009, step = 1100 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.654\n",
      "INFO:tensorflow:loss = 7.3218513, step = 1200 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.061\n",
      "INFO:tensorflow:loss = 12.865033, step = 1300 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.549\n",
      "INFO:tensorflow:loss = 6.351084, step = 1400 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.525\n",
      "INFO:tensorflow:loss = 11.366968, step = 1500 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.033\n",
      "INFO:tensorflow:loss = 2.6814349, step = 1600 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.859\n",
      "INFO:tensorflow:loss = 9.275259, step = 1700 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.801\n",
      "INFO:tensorflow:loss = 12.292616, step = 1800 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.172\n",
      "INFO:tensorflow:loss = 10.119383, step = 1900 (0.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.364\n",
      "INFO:tensorflow:loss = 17.484518, step = 2000 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.072\n",
      "INFO:tensorflow:loss = 15.2436075, step = 2100 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.062\n",
      "INFO:tensorflow:loss = 9.485586, step = 2200 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.902\n",
      "INFO:tensorflow:loss = 1.5582359, step = 2300 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.006\n",
      "INFO:tensorflow:loss = 6.7894545, step = 2400 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.531\n",
      "INFO:tensorflow:loss = 3.0862002, step = 2500 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.22\n",
      "INFO:tensorflow:loss = 8.876631, step = 2600 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.961\n",
      "INFO:tensorflow:loss = 3.3888192, step = 2700 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.948\n",
      "INFO:tensorflow:loss = 2.971579, step = 2800 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.357\n",
      "INFO:tensorflow:loss = 1.4283128, step = 2900 (0.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.384\n",
      "INFO:tensorflow:loss = 4.1364064, step = 3000 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.83\n",
      "INFO:tensorflow:loss = 8.534002, step = 3100 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.58\n",
      "INFO:tensorflow:loss = 10.292244, step = 3200 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.233\n",
      "INFO:tensorflow:loss = 7.7006454, step = 3300 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.121\n",
      "INFO:tensorflow:loss = 18.63194, step = 3400 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.957\n",
      "INFO:tensorflow:loss = 6.8191833, step = 3500 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.575\n",
      "INFO:tensorflow:loss = 5.535833, step = 3600 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.832\n",
      "INFO:tensorflow:loss = 5.663759, step = 3700 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.327\n",
      "INFO:tensorflow:loss = 8.055286, step = 3800 (0.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.721\n",
      "INFO:tensorflow:loss = 3.4869452, step = 3900 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.894\n",
      "INFO:tensorflow:loss = 16.778776, step = 4000 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.763\n",
      "INFO:tensorflow:loss = 2.628328, step = 4100 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.407\n",
      "INFO:tensorflow:loss = 11.726524, step = 4200 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.476\n",
      "INFO:tensorflow:loss = 7.5534616, step = 4300 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.84\n",
      "INFO:tensorflow:loss = 2.5335348, step = 4400 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.697\n",
      "INFO:tensorflow:loss = 14.222668, step = 4500 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.66\n",
      "INFO:tensorflow:loss = 0.4138863, step = 4600 (0.466 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4685 into /tmp/tmpcj7___ya/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.200771.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f9634bc9518>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=lambda:myInputFunc_scalar(file_train,nData_train), steps=nStep_train*nEpoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-02-20:32:36\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpcj7___ya/model.ckpt-4685\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [15/156]\n",
      "INFO:tensorflow:Evaluation [30/156]\n",
      "INFO:tensorflow:Evaluation [45/156]\n",
      "INFO:tensorflow:Evaluation [60/156]\n",
      "INFO:tensorflow:Evaluation [75/156]\n",
      "INFO:tensorflow:Evaluation [90/156]\n",
      "INFO:tensorflow:Evaluation [105/156]\n",
      "INFO:tensorflow:Evaluation [120/156]\n",
      "INFO:tensorflow:Evaluation [135/156]\n",
      "INFO:tensorflow:Evaluation [150/156]\n",
      "INFO:tensorflow:Evaluation [156/156]\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-02-20:32:37\n",
      "INFO:tensorflow:Saving dict for global step 4685: accuracy = 0.9672476, average_loss = 0.10643749, global_step = 4685, loss = 6.8119993\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4685: /tmp/tmpcj7___ya/model.ckpt-4685\n"
     ]
    }
   ],
   "source": [
    "eval_result_1 = estimator.evaluate(input_fn=lambda:myInputFunc_scalar(file_test,nData_test), steps=nStep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global_step': 4685, 'loss': 6.8119993, 'accuracy': 0.9672476, 'average_loss': 0.10643749}\n"
     ]
    }
   ],
   "source": [
    "print(eval_result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using an estimator from a Keras model with tf.data from TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMapFunc_onehot(example):\n",
    "    feature_def = {'X': tf.FixedLenFeature(nDimIn, tf.float32),\n",
    "                   'Y': tf.FixedLenFeature(1, tf.int64)}\n",
    "    features = tf.parse_single_example(example, feature_def)\n",
    "    norm = tf.constant(255, dtype=tf.float32, shape=(nDimIn,))\n",
    "    xx = tf.div(features['X'], norm)\n",
    "    yy = tf.reshape(tf.one_hot(features['Y'], nClass, dtype=tf.float32), [-1])\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input function for the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myInputFunc_onehot(filename,numData):\n",
    "    data_temp = tf.data.TFRecordDataset(filename)\n",
    "    data_temp = data_temp.shuffle(buffer_size=numData).map(myMapFunc_onehot).batch(batchSize).repeat()\n",
    "    return data_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a Keras model to an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzezltl9h\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_eval_distribute': None, '_log_step_count_steps': 100, '_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f961864a400>, '_model_dir': '/tmp/tmpzezltl9h', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_train_distribute': None, '_protocol': None, '_evaluation_master': '', '_save_checkpoints_steps': None, '_service': None, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_is_chief': True, '_save_checkpoints_secs': 600, '_master': '', '_tf_random_seed': None, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_experimental_distribute': None, '_global_id_in_cluster': 0}\n"
     ]
    }
   ],
   "source": [
    "model = myModel()\n",
    "estimator = keras.estimator.model_to_estimator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmpzezltl9h/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('/tmp/tmpzezltl9h/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: fc2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dataOut/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dataOut/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: fc2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: fc1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: fc1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpzezltl9h/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.343115, step = 0\n",
      "INFO:tensorflow:global_step/sec: 175.6\n",
      "INFO:tensorflow:loss = 0.38823017, step = 100 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.585\n",
      "INFO:tensorflow:loss = 0.30623454, step = 200 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.583\n",
      "INFO:tensorflow:loss = 0.27017453, step = 300 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.298\n",
      "INFO:tensorflow:loss = 0.44381276, step = 400 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.423\n",
      "INFO:tensorflow:loss = 0.22122486, step = 500 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.411\n",
      "INFO:tensorflow:loss = 0.23458631, step = 600 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.023\n",
      "INFO:tensorflow:loss = 0.2939775, step = 700 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.395\n",
      "INFO:tensorflow:loss = 0.25186622, step = 800 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.874\n",
      "INFO:tensorflow:loss = 0.08934962, step = 900 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.464\n",
      "INFO:tensorflow:loss = 0.1914472, step = 1000 (0.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.316\n",
      "INFO:tensorflow:loss = 0.2799527, step = 1100 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.346\n",
      "INFO:tensorflow:loss = 0.23386763, step = 1200 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.2\n",
      "INFO:tensorflow:loss = 0.13022739, step = 1300 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.54\n",
      "INFO:tensorflow:loss = 0.2688165, step = 1400 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.973\n",
      "INFO:tensorflow:loss = 0.12757486, step = 1500 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.657\n",
      "INFO:tensorflow:loss = 0.10025652, step = 1600 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.079\n",
      "INFO:tensorflow:loss = 0.06178995, step = 1700 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.969\n",
      "INFO:tensorflow:loss = 0.38850045, step = 1800 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.53\n",
      "INFO:tensorflow:loss = 0.12653774, step = 1900 (0.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.48\n",
      "INFO:tensorflow:loss = 0.1997881, step = 2000 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.424\n",
      "INFO:tensorflow:loss = 0.101094395, step = 2100 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.468\n",
      "INFO:tensorflow:loss = 0.08463234, step = 2200 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.43\n",
      "INFO:tensorflow:loss = 0.061152607, step = 2300 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.557\n",
      "INFO:tensorflow:loss = 0.19836038, step = 2400 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.568\n",
      "INFO:tensorflow:loss = 0.18402502, step = 2500 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.326\n",
      "INFO:tensorflow:loss = 0.19622898, step = 2600 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.639\n",
      "INFO:tensorflow:loss = 0.1950176, step = 2700 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.239\n",
      "INFO:tensorflow:loss = 0.14450148, step = 2800 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.451\n",
      "INFO:tensorflow:loss = 0.05950236, step = 2900 (0.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.849\n",
      "INFO:tensorflow:loss = 0.16034009, step = 3000 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.936\n",
      "INFO:tensorflow:loss = 0.10459594, step = 3100 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.449\n",
      "INFO:tensorflow:loss = 0.102305606, step = 3200 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.032\n",
      "INFO:tensorflow:loss = 0.14368361, step = 3300 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.466\n",
      "INFO:tensorflow:loss = 0.059323546, step = 3400 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.053\n",
      "INFO:tensorflow:loss = 0.08452003, step = 3500 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.462\n",
      "INFO:tensorflow:loss = 0.11348133, step = 3600 (0.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.874\n",
      "INFO:tensorflow:loss = 0.13121648, step = 3700 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.567\n",
      "INFO:tensorflow:loss = 0.08568603, step = 3800 (0.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.5\n",
      "INFO:tensorflow:loss = 0.12811038, step = 3900 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.914\n",
      "INFO:tensorflow:loss = 0.12635428, step = 4000 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.904\n",
      "INFO:tensorflow:loss = 0.048038885, step = 4100 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.346\n",
      "INFO:tensorflow:loss = 0.030349664, step = 4200 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.306\n",
      "INFO:tensorflow:loss = 0.14236182, step = 4300 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.322\n",
      "INFO:tensorflow:loss = 0.038686596, step = 4400 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.357\n",
      "INFO:tensorflow:loss = 0.019955378, step = 4500 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.702\n",
      "INFO:tensorflow:loss = 0.11344223, step = 4600 (0.527 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4685 into /tmp/tmpzezltl9h/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.019161219.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f96186739e8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=lambda:myInputFunc_onehot(file_train,nData_train), steps=nStep_train*nEpoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-02-20:33:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzezltl9h/model.ckpt-4685\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [15/156]\n",
      "INFO:tensorflow:Evaluation [30/156]\n",
      "INFO:tensorflow:Evaluation [45/156]\n",
      "INFO:tensorflow:Evaluation [60/156]\n",
      "INFO:tensorflow:Evaluation [75/156]\n",
      "INFO:tensorflow:Evaluation [90/156]\n",
      "INFO:tensorflow:Evaluation [105/156]\n",
      "INFO:tensorflow:Evaluation [120/156]\n",
      "INFO:tensorflow:Evaluation [135/156]\n",
      "INFO:tensorflow:Evaluation [150/156]\n",
      "INFO:tensorflow:Evaluation [156/156]\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-02-20:33:06\n",
      "INFO:tensorflow:Saving dict for global step 4685: accuracy = 0.96684694, global_step = 4685, loss = 0.11055692\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4685: /tmp/tmpzezltl9h/model.ckpt-4685\n"
     ]
    }
   ],
   "source": [
    "eval_result_2 = estimator.evaluate(input_fn=lambda:myInputFunc_onehot(file_test, nData_test), steps=nStep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global_step': 4685, 'accuracy': 0.96684694, 'loss': 0.11055692}\n"
     ]
    }
   ],
   "source": [
    "print(eval_result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Accessing data on google cloud (google storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before starting the tutorial, install google cloud storage by ```pip install google-cloud-storage```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Important] You cannot write or upload a file on google cloud using a VM with the default setting. If you see a permission error (related to 403 POST), go to VM instance details and edit your \"Cloud API access scopes\" on the bottom from \"defalt\" to \"full access\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "bucketname = 'your-bucket-name'\n",
    "bucket = client.get_bucket(bucketname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload files to 'gs://data-push-wearableband/temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = 'sub-folder-name/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_train = storage.Blob(target_folder+file_train, bucket) # destination\n",
    "blob_train.upload_from_filename(file_train) # source file\n",
    "blob_test = storage.Blob(target_folder+file_test, bucket) # destination\n",
    "blob_test.upload_from_filename(file_test) # source file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of files in the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp/', 'temp/mnist_test.tfrecords', 'temp/mnist_train.tfrecords']\n"
     ]
    }
   ],
   "source": [
    "filelist = []\n",
    "blobs = bucket.list_blobs(prefix=target_folder)\n",
    "for blob in blobs:\n",
    "    filelist.append(blob.name)   \n",
    "print(filelist) \n",
    "# Note that 'temp/' is included in the file list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model using the data on the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://data-push-wearableband/temp/mnist_train.tfrecords\n",
      "gs://data-push-wearableband/temp/mnist_test.tfrecords\n"
     ]
    }
   ],
   "source": [
    "fullpath_train = 'gs://'+bucketname+'/'+target_folder+file_train\n",
    "fullpath_test = 'gs://'+bucketname+'/'+target_folder+file_test\n",
    "print(fullpath_train)\n",
    "print(fullpath_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a Keras model to an estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmpzezltl9h/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('/tmp/tmpzezltl9h/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: fc2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dataOut/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dataOut/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: fc2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: fc1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: fc1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzezltl9h/model.ckpt-4685\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4685 into /tmp/tmpzezltl9h/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.26293677, step = 4685\n",
      "INFO:tensorflow:global_step/sec: 165.869\n",
      "INFO:tensorflow:loss = 0.04528652, step = 4785 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.163\n",
      "INFO:tensorflow:loss = 0.16166879, step = 4885 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.656\n",
      "INFO:tensorflow:loss = 0.089943334, step = 4985 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.386\n",
      "INFO:tensorflow:loss = 0.018729383, step = 5085 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.32\n",
      "INFO:tensorflow:loss = 0.1063158, step = 5185 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.464\n",
      "INFO:tensorflow:loss = 0.15742005, step = 5285 (0.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.458\n",
      "INFO:tensorflow:loss = 0.14449483, step = 5385 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.203\n",
      "INFO:tensorflow:loss = 0.03829495, step = 5485 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.695\n",
      "INFO:tensorflow:loss = 0.13704526, step = 5585 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.15\n",
      "INFO:tensorflow:loss = 0.037466798, step = 5685 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.641\n",
      "INFO:tensorflow:loss = 0.015689494, step = 5785 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.498\n",
      "INFO:tensorflow:loss = 0.077800296, step = 5885 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.772\n",
      "INFO:tensorflow:loss = 0.08141988, step = 5985 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.706\n",
      "INFO:tensorflow:loss = 0.09549804, step = 6085 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.783\n",
      "INFO:tensorflow:loss = 0.10685474, step = 6185 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.346\n",
      "INFO:tensorflow:loss = 0.18335311, step = 6285 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.126\n",
      "INFO:tensorflow:loss = 0.0596697, step = 6385 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.721\n",
      "INFO:tensorflow:loss = 0.041592922, step = 6485 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.153\n",
      "INFO:tensorflow:loss = 0.03766963, step = 6585 (0.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.532\n",
      "INFO:tensorflow:loss = 0.07494867, step = 6685 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.859\n",
      "INFO:tensorflow:loss = 0.047436465, step = 6785 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.785\n",
      "INFO:tensorflow:loss = 0.10758423, step = 6885 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.557\n",
      "INFO:tensorflow:loss = 0.09009351, step = 6985 (0.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.325\n",
      "INFO:tensorflow:loss = 0.058775768, step = 7085 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.574\n",
      "INFO:tensorflow:loss = 0.07727949, step = 7185 (0.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.023\n",
      "INFO:tensorflow:loss = 0.028509261, step = 7285 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.929\n",
      "INFO:tensorflow:loss = 0.0125967655, step = 7385 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.106\n",
      "INFO:tensorflow:loss = 0.071365595, step = 7485 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.512\n",
      "INFO:tensorflow:loss = 0.062833846, step = 7585 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.068\n",
      "INFO:tensorflow:loss = 0.07584804, step = 7685 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.244\n",
      "INFO:tensorflow:loss = 0.16068706, step = 7785 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.305\n",
      "INFO:tensorflow:loss = 0.05271759, step = 7885 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.155\n",
      "INFO:tensorflow:loss = 0.069579884, step = 7985 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.201\n",
      "INFO:tensorflow:loss = 0.07663117, step = 8085 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.013\n",
      "INFO:tensorflow:loss = 0.03538336, step = 8185 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.323\n",
      "INFO:tensorflow:loss = 0.025143351, step = 8285 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.716\n",
      "INFO:tensorflow:loss = 0.10386059, step = 8385 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.331\n",
      "INFO:tensorflow:loss = 0.03639785, step = 8485 (0.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.378\n",
      "INFO:tensorflow:loss = 0.025539573, step = 8585 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.973\n",
      "INFO:tensorflow:loss = 0.11529465, step = 8685 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.505\n",
      "INFO:tensorflow:loss = 0.024646323, step = 8785 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.294\n",
      "INFO:tensorflow:loss = 0.017728638, step = 8885 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.006\n",
      "INFO:tensorflow:loss = 0.05596263, step = 8985 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.408\n",
      "INFO:tensorflow:loss = 0.026135616, step = 9085 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.403\n",
      "INFO:tensorflow:loss = 0.06356065, step = 9185 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.996\n",
      "INFO:tensorflow:loss = 0.014010385, step = 9285 (0.617 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9370 into /tmp/tmpzezltl9h/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.053213447.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f96186739e8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=lambda:myInputFunc_onehot(file_train, nData_train), steps=nStep_train*nEpoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-02-20:33:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpzezltl9h/model.ckpt-9370\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [15/156]\n",
      "INFO:tensorflow:Evaluation [30/156]\n",
      "INFO:tensorflow:Evaluation [45/156]\n",
      "INFO:tensorflow:Evaluation [60/156]\n",
      "INFO:tensorflow:Evaluation [75/156]\n",
      "INFO:tensorflow:Evaluation [90/156]\n",
      "INFO:tensorflow:Evaluation [105/156]\n",
      "INFO:tensorflow:Evaluation [120/156]\n",
      "INFO:tensorflow:Evaluation [135/156]\n",
      "INFO:tensorflow:Evaluation [150/156]\n",
      "INFO:tensorflow:Evaluation [156/156]\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-02-20:33:40\n",
      "INFO:tensorflow:Saving dict for global step 9370: accuracy = 0.96935093, global_step = 9370, loss = 0.10938837\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9370: /tmp/tmpzezltl9h/model.ckpt-9370\n"
     ]
    }
   ],
   "source": [
    "eval_result_3 = estimator.evaluate(input_fn=lambda:myInputFunc_onehot(fullpath_test, nData_test), steps=nStep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global_step': 9370, 'accuracy': 0.96935093, 'loss': 0.10938837}\n"
     ]
    }
   ],
   "source": [
    "print(eval_result_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
